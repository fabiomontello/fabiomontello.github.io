<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<title>Fabio Montello</title>
        <meta name="description" content="Fabio Montello is a interactive graphic designer and a multimedia content creator." />
        <link rel="stylesheet" type="text/css" href="./css/style.css">
        <meta name="keywords" content="Fabio Montello,Fabio, Montello,fabio montello,interactive graphic design,multimedia content creator,processing,p5.js,d3.js,graphic design,data design,data designer,multimedia production,multimedia,multimedia design">
        <meta name="robots" content="index,follow">
        <link rel="stylesheet" type="text/css" href="../css/style.css">
        <link href="https://fonts.googleapis.com/css?family=Quicksand" rel="stylesheet">
        <link href="https://fonts.googleapis.com/css?family=Raleway" rel="stylesheet">
        <link rel="shortcut icon" href="../img/favicon.ico" type="image/x-icon">
        <link rel="icon" href="../img/favicon.ico" type="image/x-icon">
	</head>
	<body>
    <div>
        <div class="header container">
           <div class="myname"><h1><a href="../index.html">FABIO MONTELLO</a></h1></div>
           <div class="about"><a href="../index.html">Portfolio</a> | <a href="../about.html">About</a></div>
        </div>
        <div class="content container">
            <div class="topic"><h2>VIDEO FRAME INTERPOLATION VIA ADAPTIVE CONVOLUTION</h2></div>
           
            <div class="card">
                <iframe width="600" height="315"
                src="https://www.youtube.com/embed/bURlDu8YjQk">
                </iframe>
                <p>This is a project for the course of Neural Networks for Data Science Applications. It is based on <a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Niklaus_Video_Frame_Interpolation_CVPR_2017_paper.pdf" rel="nofollow">this paper</a> by Niklaus,  Mai and Liu. The purpose of this project is to reproduce the video frame interpolation via adaptive convolution as presented in the paper, with Tensorflow via Google Colab.</p>
                <h5><a id="user-content-report" class="anchor" aria-hidden="true" href="#report">
                
                </a>REPORT</h5>
                <p>This paper presents a video frame interpolation method that combines in a single fully convolutional neural network model the two basic steps of frame interpolation: model motion estimation and pixel synthesis.The neural network model considers pixel synthesis for the interpolated frame as local convolution over two input frames. The convolution kernel captures both the local motion between the input frames and the coefficients for pixel synthesis. The formulation of video interpolation as a single convolution process allows the handle of challenges like occlusion, blur, and abrupt brightness change and enables high-quality video frame interpolation.
                Specifically, for a pixel (x, y) in the interpolated frame, this deep neural network takes two receptive field patches R1 and R2 centered at that pixel as input and estimates a convolution kernel K. This convolution kernel is used to convolve with the input patches P1 and P2 to synthesize the output pixel, as illustrated in Figure 1.</p>
                <div>
                <a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/fabiomontello/Video_Frame_Interpolation-A_NN_Project/master/imgs/figure1.png"><img src="https://raw.githubusercontent.com/fabiomontello/Video_Frame_Interpolation-A_NN_Project/master/imgs/figure1.png" alt="Figure 1" width="600" style="max-width:100%;"></a>
                </div>
                Compared to other techniques of frame interpolation, this methos  to have some advantages:
                <ol>
                <li>It is able to make proper trade-offs among competing constraints and can provide a robust interpolation approach.</li>
                <li>Can be directly trained end to end using widely available video data, without any difficult-to-obtain ground truth data like optical flow.</li>
                <li>This method is able to generate high-quality frame interpolation results for challenging videos such as those with occlusion, blurring artifacts, and abrupt brightness change, as demonstrated in the paper and reproduced in this project.</li>
                </ol>
                <h5><a id="user-content-network-architecture" class="anchor" aria-hidden="true" href="#network-architecture"></a>NETWORK ARCHITECTURE</h5>
                <p>The neural network model presented in the paper and reproduced in this project consists of several convolutional layers as well as down-convolutions as alternatives to max-pooling layers. The architecture of the network is the following:</p>
                <div>
                <a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/fabiomontello/Video_Frame_Interpolation-A_NN_Project/master/imgs/figure2.png"><img src="https://raw.githubusercontent.com/fabiomontello/Video_Frame_Interpolation-A_NN_Project/master/imgs/figure2.png" alt="Figure 2" width="400" style="max-width:100%;"></a>
                </div>
                The model takes in input two images (each with the three channels), making the input tensor of shape (79, 79, 3). The output of the model is a kernel of shape (82,41) which needs to be convolved with a patch (crop) of the input images concatenated in order to produce the output color. The patch shape is (82,41,3) and convolved with the kernel will return respectively the value in each channel. A larger receptive field than the patch is used in order to better handle the aperture problem in motion estimation. Rectified Linear Units is used as activation functions, meanwhile and Batch Normalization is used for regularization. A critical constraint is that the coefficients of the output convolution kernel should be non-negative and sum up to one. Therefore, we connect the final convolutional layer to a spatial softmax layer to output the convolution kernel.
                <p>Project link: <a href="https://github.com/fabiomontello/Video_Frame_Interpolation-A_NN_Project" rel="nofollow">https://github.com/fabiomontello/Video_Frame_Interpolation-A_NN_Project</a></p>
                <p>Project notebook: <a href="https://github.com/fabiomontello/Video_Frame_Interpolation-A_NN_Project/blob/master/Exam_Neural_Networks_Fabio_Montello_1834411.ipynb" rel="nofollow">https://github.com/fabiomontello/Video_Frame_Interpolation-A_NN_Project/blob/master/Exam_Neural_Networks_Fabio_Montello_1834411.ipynb</a></p>
                <p>Paper link: <a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Niklaus_Video_Frame_Interpolation_CVPR_2017_paper.pdf" rel="nofollow">http://openaccess.thecvf.com/content_cvpr_2017/papers/Niklaus_Video_Frame_Interpolation_CVPR_2017_paper.pdf</a></p>
                <p>Dataset <a href="https://www.di.ens.fr/~laptev/actions/" rel="nofollow">https://www.di.ens.fr/~laptev/actions/</a></p>
                
            </div>
            
        </div>
    </div>
        
        <button onclick="topFunction()" id="myBtn" title="Go to top">TOP</button>
	</body>
</html>


